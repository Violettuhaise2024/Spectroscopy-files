{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAMCA Infrared Spectroscopy Workshop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic: Manipulation of infrared spectroscopy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python offers a very flexible and powerfull packages to manipulate data. The main package is **Pandas**. pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language. \n",
    "\n",
    "If you installed python with the anaconda distribution, pandas is already installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulation of infrared spectroscopy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infrared spectroscopy data comes usually in a format table where samples are rows and columns have values of absorbance, age, species, etc. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, it is best practice to import all the packages we are going to use for our script. For this, we use import <module_name> as <alt_name>. The alt_names of the packages are  pre-defined abreviations, in order to everyone can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of data that python import\n",
    "\n",
    "The so-called CSV (Comma Separated Values) format is the most common import and export format for spreadsheets and databases. We will use csv files in this example. \n",
    "\n",
    "To import data into our jupyter notebook, we use the command pd.read_csv. This function uses as argument the path where the file is located in your computer.\n",
    "Sometimes depending on the file, you will ne to specified the separation that uses the file. \n",
    "\n",
    "Although, csv are very common, you can also find tab delimited files. For this type of files, you need to specify the argument **sep = '\\t'**. This symbol means tab delimited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "mosquito_data = pd.read_csv(\"/Users/mauropazmino/Documents/University/Workhops/PAMCA_workshop/Workshop/Python Basics I/Datasets/UV_pilot_toydataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataFrame:** \n",
    "\n",
    "- Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
    "\n",
    "- Data structure also contains labeled axes (rows and columns). Arithmetic operations align on both row and column labels. Can be thought of as a dict-like container for Series objects. The primary pandas data structure\n",
    "\n",
    "By importing the data as DataFrame, we can use pandas atrributes and functions directly to the data for manipulation, slicing and subsetting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data\n",
    "\n",
    "After importing the data, you can see if it was imported correctly by using the function head(). It will display the first 5 rows of the dataset. You can increase the number of rows by puttig a integer as argument of the function. Moreover, you can use the function tail() to see the last 5 rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "\n",
    "print(mosquito_data.head()) # default setting. It will show 5 rows\n",
    "print(mosquito_data.head(10)) # it will show 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data\n",
    "\n",
    "Most of the time you will spend in data analysis and machine learning will focus on cleaning your data. This process involves from renaming column names, sorting data, slice it to create new columns with new values. Pandas offers a lot of functionality that allows this process to be as easy as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming columns\n",
    "\n",
    "Renaming columns is a easy process with the function **rename**. This function has a argument called **columns** that receives a dictionary. This dictionary will contain the old name of the column and the new names you want to use to replace the old ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the name of the columns\n",
    "\n",
    "## The dictionary syntax is as follows: {old column name: new column name}\n",
    "## inplace = True will make the changes directly to the dataset\n",
    "\n",
    "mosquito_data.rename(columns={\"Sp\":\"Specie\", \"Reeplicate\":\"Replicate\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosquito_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice data\n",
    "\n",
    "We often want to work with subsets of a DataFrame object. There are different ways to accomplish this including: using labels (column headings), numeric ranges, or specific x,y index locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting data using Labels (Column Headings)\n",
    "We use square brackets [] to select a subset of a Python object. For example, we can select all data from a column named Species from our dataset. There are two ways to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Select specific columns by column name\n",
    "print(mosquito_data[\"Specie\"])\n",
    "\n",
    "# Method: 2 Select specific columns by column name\n",
    "print(mosquito_data.Specie)\n",
    "\n",
    "# Save the column in a new variable\n",
    "species = mosquito_data['Specie']\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Range based Subsets: Slicing\n",
    "\n",
    "You can extract not only single columns, but also ranges of columns by label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub setting various columns from the DataFrame using lists\n",
    "\n",
    "## create a list of the columns you want to slice\n",
    "list_columns = ['Specie', 'Exposed', 'Sex'] \n",
    "\n",
    "# select the columns\n",
    "mosquito_data[list_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing Subsets of Rows in Python\n",
    "Slicing using the [ ] operator selects a set of rows and/or columns from a DataFrame. To slice out a set of rows, you use the following syntax: data[start:stop]. When slicing in pandas the start bound is included in the output. The stop bound is one step BEYOND the row you want to select. So if you want to select rows 0, 1 and 2 your code would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting specific rows by using index\n",
    "mosquito_data[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using conditions to slice data\n",
    "\n",
    "As seen before, we can also use conditionals to slide data from a data frame. However, we must use symbols instead of the conjuctions **and** and the disjuction **or** \n",
    "\n",
    "- And = & \n",
    "- Or = |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose rows based on conditions\n",
    "\n",
    "mosquito_data[mosquito_data['Exposed'] == 'YES'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosquito_data[(mosquito_data['Sex'] == 'F') & (mosquito_data[\"4000\"] > 0.0081)]\n",
    "\n",
    "#filter_df = mosquito_data[(mosquito_data[\"Sex\"] == \"F\") | (mosquito_data[\"Replicate\"] == 'R1')]\n",
    "#filter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing Subsets of Rows and Columns in Python\n",
    "\n",
    "We can select specific ranges of our data in both the row and column directions using either label or integer-based indexing.\n",
    "\n",
    "## .loc and .iloc\n",
    "\n",
    "### .loc\n",
    "loc is primarily **label** based, but may also be used with a boolean array. \n",
    "\n",
    "Allowed inputs are:\n",
    "\n",
    "- A single label, e.g. 5 or 'a' (Note that 5 is interpreted as a label of the index. This use is not an integer position along the index.).\n",
    "\n",
    "- A list or array of labels ['a', 'b', 'c'].\n",
    "\n",
    "- A slice object with labels 'a':'f' (Note that contrary to usual Python slices, both the start and the stop are included, when present in the index! See Slicing with labels and Endpoints are inclusive.)\n",
    "\n",
    "- A boolean array (any NA values will be treated as False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = mosquito_data.loc[:,'Sex':'4000']\n",
    "df_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .iloc\n",
    "\n",
    ".iloc is primarily integer position based (from 0 to length-1 of the axis), but may also be used with a boolean array. .iloc will raise IndexError if a requested indexer is out-of-bounds, except slice indexers which allow out-of-bounds indexing. (this conforms with Python/NumPy slice semantics). Allowed inputs are:\n",
    "\n",
    "- An integer e.g. 5.\n",
    "\n",
    "- A list or array of integers [4, 3, 0].\n",
    "\n",
    "- A slice object with ints 1:7.\n",
    "\n",
    "- A boolean array (any NA values will be treated as False).\n",
    "\n",
    "- A callable function with one argument (the calling Series or DataFrame) and that returns valid output for indexing (one of the above).\n",
    "\n",
    "- A tuple of row (and column) indices whose elements are one of the above inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosquito_data.iloc[:,0:2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the data\n",
    "\n",
    "Pandas offers functions that allow us to summarize our data quite fast. We can know how many classes of a specific column we have, or and how many observations per class do we have. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting values for each class \n",
    "\n",
    "You can print how many values you have from each classes of a specific column with the function **value_counts()**. \n",
    "\n",
    "**Note**: Pandas allows us to \"chain\" its functions. Each function will work on the result of the previous function. The syntax to chain functions on pandas is:\n",
    "\n",
    "dataframe.function1().function2().function3().."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many observation of each class we have in the column Age.\n",
    "\n",
    "mosquito_data[\"Sex\"].value_counts()\n",
    "\n",
    "# Chaining a function to sort the resulting counting values from lowest to highest (or alphabetically)\n",
    "mosquito_data[\"Sex\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the describe function will count how many observations (rows) are in a specific column, how many unique values there are and which value is the most frequent\n",
    " \n",
    "print(mosquito_data['Sex'].describe())\n",
    "#print(mosquito_data['Sex'].value_counts())\n",
    "#print(mosquito_data['Age'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouby\n",
    "\n",
    "A groupby operation involves some combination of splitting the object, applying a function, and combining the results. This can be used to group large amounts of data and compute operations on these groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You call bygroup and pass the name of the column yoy want to group. Then you pass the column name in which you want to perform the the count.\n",
    "\n",
    "mosquito_data.groupby(['Sex'])[\"Specie\"].count()\n",
    "\n",
    "# you can add more than one column to group\n",
    "mosquito_data.groupby(['Sex',\"Replicate\"])[\"Specie\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can add more than one column to group\n",
    "mosquito_data.groupby(['Sex',\"Specie\"])[\"4000\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take the mean of a row or rows\n",
    "mosquito_data.loc[0:4,'4000':'420'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new columns\n",
    "\n",
    "We can create new columns based on other column values or new values. We use the operator [] and add the name of the new column, then we specify what values the new column will have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new columns\n",
    "\n",
    "# create a column called \"New column\" that is equal to the values of column '4000' multiplied by 100\n",
    "mosquito_data['New column'] = mosquito_data['4000']*100\n",
    "mosquito_data['New column']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosquito_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erase columns\n",
    "\n",
    "You can also, erase columns using the function drop. You need to specify the name of the column, axis (axis=0 if it is a row and axis =1 if it is a column) and inplace (True to make the changes directly into the DataFrame or False if not). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Erase columns\n",
    "## axis = 1 Indicates that a column will be erased. \n",
    "## inplace = True is used to make the changes directly to the dataset. If it is set to false, the changes will no be permanent.  \n",
    "\n",
    "mosquito_data.drop(\"ID\", axis=1, inplace=True)\n",
    "mosquito_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you run this line once, it will erase the column. Therefore, if you run it again it will give you a KeyError, meaning that the column you try to erase does not exist anymore. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace\n",
    "\n",
    "You can replace the values of the rows of specific columns by using the function .replace(). You pass a dictionary with the old values and new value you want to replace. You can replace as many values you want in many columns as you want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace values\n",
    "## replace the value '01d' for '1 day old' in the column Age.\n",
    "\n",
    "replace_values = {'NOU' : \"NO\"} \n",
    "mosquito_data.replace({\"Exposed\": replace_values}, inplace=True)\n",
    "\n",
    "mosquito_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_values = {'AG' : \"An. gambiae\"}\n",
    "replace_values_2 = {'F': 'females', 'M': 'males'}\n",
    "mosquito_data.replace({\"Specie\": replace_values, \"Sex\": replace_values_2}, inplace=True)\n",
    "\n",
    "mosquito_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosquito_data.groupby(['Sex'])['Replicate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercises\n",
    "\n",
    "1. Import the dataset (again so you have all the complete dataset)\n",
    "2. Change columns Exposed to Exposed_UV\n",
    "3. Erase column ID and Replicate\n",
    "4. Create a new column called: NEW that is the value of column 402 divided by 2\n",
    "5. Create a variable called mean_spectra and assign the mean spectra of all the samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://realpython.com/pandas-groupby/\n",
    "- https://datacarpentry.org/python-ecology-lesson/03-index-slice-subset.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
